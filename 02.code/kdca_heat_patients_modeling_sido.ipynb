{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 10:58:43.865769: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-02 10:58:43.896376: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, LSTM, Dense\n",
    "\n",
    "import gc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/home/hwchoi/001.project/data/T_PATIENTS_DAILY_WHOLE_0731.csv'\n",
    "df_raw=pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sido Modeling (시도별 환자수 예측)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. create_date sorting 적용 / whole features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "# create_date에 대한 sorting 적용\n",
    "df_raw['create_date'] = pd.to_datetime(df_raw['create_date'])\n",
    "df_raw.sort_values(by='create_date', inplace=True)\n",
    "# 결측치 채우기\n",
    "df_raw = df_raw.fillna(0)\n",
    "\n",
    "features=['weekend_yn', 'sido_cd', 'min_ta', 'max_ta', 'mean_ta', 'gap_ta', 'min_tafeel', 'max_tafeel', 'mean_tafeel', 'gap_tafeel', 'min_hm', 'max_hm',\n",
    "       'mean_hm', 'gap_hm', 'min_wbtemp', 'max_wbtemp', 'mean_wbtemp', 'gap_wbtemp', 'min_ws', 'max_ws', 'mean_ws', 'tropical_3days',\n",
    "       'heatwave_temp', 'heatalert_temp', 'ta_min_3days', 'ta_max_3days', 'gap_ta_minmax', 'popular_man', 'popular_woman', 'agriculture_man',\n",
    "       'agriculture_woman', 'ta_min_am', 'ta_max_am', 'ta_mean_am', 'ta_min_pm', 'ta_max_pm', 'ta_mean_pm', 'ta_min_six_am1',\n",
    "       'ta_max_six_am1', 'ta_mean_six_am1', 'ta_min_six_am2', 'ta_max_six_am2',\n",
    "       'ta_mean_six_am2', 'ta_min_six_pm1', 'ta_max_six_pm1', 'ta_mean_six_pm1', 'ta_min_six_pm2', 'ta_max_six_pm2', 'ta_mean_six_pm2']\n",
    "target='patientsCnt'\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 스케일링\n",
    "scaler = StandardScaler()\n",
    "df_raw[features] = scaler.fit_transform(df_raw[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 시퀀스 준비 함수\n",
    "def create_sequences(data, features, target, sequence_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    dates = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[features].iloc[i:i+sequence_length].values)\n",
    "        y.append(data[target].iloc[i+sequence_length])\n",
    "        dates.append(data['create_date'].iloc[i+sequence_length])\n",
    "    return np.array(X), np.array(y), np.array(dates)\n",
    "\n",
    "sequence_length = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 모델 학습 및 평가\n",
    "def train_rnn_model(data, sido_cd, features, target, sequence_length):\n",
    "    data_sido = data[data['sido_cd'] == sido_cd]\n",
    "    X, y, dates = create_sequences(data_sido, features, target, sequence_length)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)\n",
    "    \n",
    "    rnn_model = Sequential()\n",
    "    rnn_model.add(SimpleRNN(50, activation='relu', input_shape=(sequence_length, len(features))))\n",
    "    rnn_model.add(Dense(1))\n",
    "    rnn_model.compile(optimizer='adam', loss='mse')\n",
    "    rnn_model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))\n",
    "    \n",
    "    rnn_predictions = rnn_model.predict(X_test).flatten()\n",
    "    rnn_mae = mean_absolute_error(y_test, rnn_predictions)\n",
    "    rnn_mse = mean_squared_error(y_test, rnn_predictions)\n",
    "    rnn_r2 = r2_score(y_test, rnn_predictions)\n",
    "    \n",
    "    # 메모리 초기화\n",
    "    del rnn_model\n",
    "    gc.collect()\n",
    "    \n",
    "    return {'mae': rnn_mae, 'mse': rnn_mse, 'r2': rnn_r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델 학습 및 평가\n",
    "def train_lstm_model(data, sido_cd, features, target, sequence_length):\n",
    "    data_sido = data[data['sido_cd'] == sido_cd]\n",
    "    X, y, dates = create_sequences(data_sido, features, target, sequence_length)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)\n",
    "    \n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(LSTM(50, activation='relu', input_shape=(sequence_length, len(features))))\n",
    "    lstm_model.add(Dense(1))\n",
    "    lstm_model.compile(optimizer='adam', loss='mse')\n",
    "    lstm_model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))\n",
    "    \n",
    "    lstm_predictions = lstm_model.predict(X_test).flatten()\n",
    "    lstm_mae = mean_absolute_error(y_test, lstm_predictions)\n",
    "    lstm_mse = mean_squared_error(y_test, lstm_predictions)\n",
    "    lstm_r2 = r2_score(y_test, lstm_predictions)\n",
    "    \n",
    "    # 메모리 초기화\n",
    "    del lstm_model\n",
    "    gc.collect()\n",
    "    \n",
    "    return {'mae': lstm_mae, 'mse': lstm_mse, 'r2': lstm_r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest 모델 학습 및 평가\n",
    "def train_rf_model(data, sido_cd, features, target, sequence_length):\n",
    "    data_sido = data[data['sido_cd'] == sido_cd]\n",
    "    X, y, dates = create_sequences(data_sido, features, target, sequence_length)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)\n",
    "    \n",
    "    X_train_2d = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test_2d = X_test.reshape(X_test.shape[0], -1)\n",
    "    \n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=11)\n",
    "    rf_model.fit(X_train_2d, y_train)\n",
    "    \n",
    "    rf_predictions = rf_model.predict(X_test_2d)\n",
    "    rf_mae = mean_absolute_error(y_test, rf_predictions)\n",
    "    rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "    rf_r2 = r2_score(y_test, rf_predictions)\n",
    "    \n",
    "    # 메모리 초기화\n",
    "    del rf_model\n",
    "    gc.collect()\n",
    "    \n",
    "    return {'mae': rf_mae, 'mse': rf_mse, 'r2': rf_r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost 모델 학습 및 평가\n",
    "def train_xgb_model(data, sido_cd, features, target, sequence_length):\n",
    "    data_sido = data[data['sido_cd'] == sido_cd]\n",
    "    X, y, dates = create_sequences(data_sido, features, target, sequence_length)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)\n",
    "    \n",
    "    X_train_2d = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test_2d = X_test.reshape(X_test.shape[0], -1)\n",
    "    \n",
    "    xgb_model = XGBRegressor(n_estimators=100, random_state=11)\n",
    "    xgb_model.fit(X_train_2d, y_train)\n",
    "    \n",
    "    xgb_predictions = xgb_model.predict(X_test_2d)\n",
    "    xgb_mae = mean_absolute_error(y_test, xgb_predictions)\n",
    "    xgb_mse = mean_squared_error(y_test, xgb_predictions)\n",
    "    xgb_r2 = r2_score(y_test, xgb_predictions)\n",
    "    \n",
    "    # 메모리 초기화\n",
    "    del xgb_model\n",
    "    gc.collect()\n",
    "    \n",
    "    return {'mae': xgb_mae, 'mse': xgb_mse, 'r2': xgb_r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0.24972405276789855...\n",
      "Epoch 1/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 35.7581 - val_loss: 17.2179\n",
      "Epoch 2/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.9479 - val_loss: 14.3861\n",
      "Epoch 3/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.9621 - val_loss: 12.8736\n",
      "Epoch 4/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.4551 - val_loss: 13.1424\n",
      "Epoch 5/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.8734 - val_loss: 13.7623\n",
      "Epoch 6/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.5114 - val_loss: 11.6605\n",
      "Epoch 7/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.5398 - val_loss: 11.3650\n",
      "Epoch 8/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.6121 - val_loss: 12.2739\n",
      "Epoch 9/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.4697 - val_loss: 9.9852\n",
      "Epoch 10/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.7250 - val_loss: 12.6351\n",
      "Epoch 11/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.5279 - val_loss: 12.5408\n",
      "Epoch 12/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.2773 - val_loss: 9.7041\n",
      "Epoch 13/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.5559 - val_loss: 9.3279\n",
      "Epoch 14/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.8506 - val_loss: 10.4923\n",
      "Epoch 15/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.1563 - val_loss: 10.7141\n",
      "Epoch 16/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.6673 - val_loss: 10.2468\n",
      "Epoch 17/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7596 - val_loss: 9.2111\n",
      "Epoch 18/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5810 - val_loss: 12.4251\n",
      "Epoch 19/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7137 - val_loss: 9.8922\n",
      "Epoch 20/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4610 - val_loss: 10.3528\n",
      "Epoch 21/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6937 - val_loss: 10.4246\n",
      "Epoch 22/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2528 - val_loss: 9.7616\n",
      "Epoch 23/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8694 - val_loss: 8.5339\n",
      "Epoch 24/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0021 - val_loss: 8.6188\n",
      "Epoch 25/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6723 - val_loss: 7.8305\n",
      "Epoch 26/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3552 - val_loss: 8.9678\n",
      "Epoch 27/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.5470 - val_loss: 9.3145\n",
      "Epoch 28/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3886 - val_loss: 8.8359\n",
      "Epoch 29/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3868 - val_loss: 7.8865\n",
      "Epoch 30/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5975 - val_loss: 9.7362\n",
      "Epoch 31/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2446 - val_loss: 8.1921\n",
      "Epoch 32/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5097 - val_loss: 9.5809\n",
      "Epoch 33/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7030 - val_loss: 10.1715\n",
      "Epoch 34/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1334 - val_loss: 8.7235\n",
      "Epoch 35/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4834 - val_loss: 10.1920\n",
      "Epoch 36/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3410 - val_loss: 9.3667\n",
      "Epoch 37/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5595 - val_loss: 10.4002\n",
      "Epoch 38/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7810 - val_loss: 9.1472\n",
      "Epoch 39/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5729 - val_loss: 8.3789\n",
      "Epoch 40/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5365 - val_loss: 9.5147\n",
      "Epoch 41/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2043 - val_loss: 9.9616\n",
      "Epoch 42/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8851 - val_loss: 9.6457\n",
      "Epoch 43/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6056 - val_loss: 10.3416\n",
      "Epoch 44/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3284 - val_loss: 8.7876\n",
      "Epoch 45/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.6219 - val_loss: 9.3357\n",
      "Epoch 46/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1506 - val_loss: 9.7081\n",
      "Epoch 47/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.9122 - val_loss: 9.3358\n",
      "Epoch 48/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0104 - val_loss: 9.0409\n",
      "Epoch 49/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3900 - val_loss: 10.4924\n",
      "Epoch 50/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.9794 - val_loss: 8.9581\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Epoch 1/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 27.0279 - val_loss: 13.1081\n",
      "Epoch 2/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17.0346 - val_loss: 11.3031\n",
      "Epoch 3/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.0120 - val_loss: 13.2395\n",
      "Epoch 4/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16.0052 - val_loss: 12.1414\n",
      "Epoch 5/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.1601 - val_loss: 10.0435\n",
      "Epoch 6/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11.8918 - val_loss: 10.8261\n",
      "Epoch 7/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11.7590 - val_loss: 13.3618\n",
      "Epoch 8/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.9035 - val_loss: 8.1346\n",
      "Epoch 9/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.2179 - val_loss: 10.1484\n",
      "Epoch 10/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.4931 - val_loss: 8.3779\n",
      "Epoch 11/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.7031 - val_loss: 8.4914\n",
      "Epoch 12/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.7419 - val_loss: 10.8473\n",
      "Epoch 13/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.3617 - val_loss: 8.1594\n",
      "Epoch 14/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2051 - val_loss: 8.1556\n",
      "Epoch 15/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.3428 - val_loss: 9.4700\n",
      "Epoch 16/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1864 - val_loss: 9.9661\n",
      "Epoch 17/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7448 - val_loss: 12.9257\n",
      "Epoch 18/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.3073 - val_loss: 7.7738\n",
      "Epoch 19/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.5167 - val_loss: 8.4177\n",
      "Epoch 20/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.9877 - val_loss: 8.7864\n",
      "Epoch 21/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.7464 - val_loss: 10.2386\n",
      "Epoch 22/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5801 - val_loss: 9.6124\n",
      "Epoch 23/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.8757 - val_loss: 10.8534\n",
      "Epoch 24/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3755 - val_loss: 9.6430\n",
      "Epoch 25/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4304 - val_loss: 10.0905\n",
      "Epoch 26/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4840 - val_loss: 9.1118\n",
      "Epoch 27/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7706 - val_loss: 9.2650\n",
      "Epoch 28/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0809 - val_loss: 10.5905\n",
      "Epoch 29/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1036 - val_loss: 9.7730\n",
      "Epoch 30/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5384 - val_loss: 10.9868\n",
      "Epoch 31/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5849 - val_loss: 9.7942\n",
      "Epoch 32/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1714 - val_loss: 9.1531\n",
      "Epoch 33/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1855 - val_loss: 9.9469\n",
      "Epoch 34/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6281 - val_loss: 10.5911\n",
      "Epoch 35/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2904 - val_loss: 10.1847\n",
      "Epoch 36/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4854 - val_loss: 10.4622\n",
      "Epoch 37/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4011 - val_loss: 10.1063\n",
      "Epoch 38/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9799 - val_loss: 10.4191\n",
      "Epoch 39/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1534 - val_loss: 10.5114\n",
      "Epoch 40/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2045 - val_loss: 9.9452\n",
      "Epoch 41/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7830 - val_loss: 9.7673\n",
      "Epoch 42/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.2629 - val_loss: 10.4083\n",
      "Epoch 43/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4941 - val_loss: 9.6277\n",
      "Epoch 44/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.1924 - val_loss: 10.0351\n",
      "Epoch 45/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3338 - val_loss: 10.4736\n",
      "Epoch 46/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8313 - val_loss: 10.4519\n",
      "Epoch 47/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7093 - val_loss: 10.1568\n",
      "Epoch 48/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3504 - val_loss: 10.0611\n",
      "Epoch 49/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8191 - val_loss: 9.4315\n",
      "Epoch 50/50\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7944 - val_loss: 10.2558\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# 시도별 결과 저장 딕셔너리\n",
    "sido_results = {}\n",
    "\n",
    "# 시도별 모델 학습 및 평가\n",
    "sido_cds = df_raw['sido_cd'].unique()\n",
    "for sido_cd in sido_cds:\n",
    "    print(f'Processing {sido_cd}...')\n",
    "    sido_results[sido_cd] = {\n",
    "        'RNN': train_rnn_model(df_raw, sido_cd, features, target, sequence_length),\n",
    "        'LSTM': train_lstm_model(df_raw, sido_cd, features, target, sequence_length),\n",
    "        'RandomForest': train_rf_model(df_raw, sido_cd, features, target, sequence_length),\n",
    "        'XGBoost': train_xgb_model(df_raw, sido_cd, features, target, sequence_length)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_map = {'39': '제주특별자치도', '32': '강원특별자치도', '25': '대전광역시','21': '부산광역시',\n",
    "    '24': '광주광역시','26': '울산광역시', '38': '경상남도','23': '인천광역시',\n",
    "    '31': '경기도','33': '충청북도', '22': '대구광역시','35': '전북특별자치도',\n",
    "    '37': '경상북도','29': '세종특별자치시','36': '전라남도','11': '서울특별시','34': '충청남도'\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kdca",
   "language": "python",
   "name": "kdca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
